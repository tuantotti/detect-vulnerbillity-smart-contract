{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ab774d",
   "metadata": {
    "id": "C2lOX1Sr0iSD",
    "papermill": {
     "duration": 0.011671,
     "end_time": "2023-11-28T10:10:29.707683",
     "exception": false,
     "start_time": "2023-11-28T10:10:29.696012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import and connect to gg drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68270e63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:29.731478Z",
     "iopub.status.busy": "2023-11-28T10:10:29.731117Z",
     "iopub.status.idle": "2023-11-28T10:10:29.735157Z",
     "shell.execute_reply": "2023-11-28T10:10:29.734429Z"
    },
    "id": "diMysT7u0l9M",
    "outputId": "58566556-480a-4529-ddf9-19e8b1b2db12",
    "papermill": {
     "duration": 0.017972,
     "end_time": "2023-11-28T10:10:29.737051",
     "exception": false,
     "start_time": "2023-11-28T10:10:29.719079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e55f0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:29.760693Z",
     "iopub.status.busy": "2023-11-28T10:10:29.760182Z",
     "iopub.status.idle": "2023-11-28T10:10:29.763637Z",
     "shell.execute_reply": "2023-11-28T10:10:29.762889Z"
    },
    "id": "q-E2Mi_30otZ",
    "outputId": "ae9bc397-fff3-4883-8ea0-0cd1a7207007",
    "papermill": {
     "duration": 0.017272,
     "end_time": "2023-11-28T10:10:29.765551",
     "exception": false,
     "start_time": "2023-11-28T10:10:29.748279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cd /content/drive/MyDrive/lab/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483fdda7",
   "metadata": {
    "id": "7ShsVEooMxRM",
    "papermill": {
     "duration": 0.011046,
     "end_time": "2023-11-28T10:10:29.788525",
     "exception": false,
     "start_time": "2023-11-28T10:10:29.777479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ebd913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:29.811817Z",
     "iopub.status.busy": "2023-11-28T10:10:29.811322Z",
     "iopub.status.idle": "2023-11-28T10:10:45.854381Z",
     "shell.execute_reply": "2023-11-28T10:10:45.853625Z"
    },
    "id": "_fJlPHWD0qcl",
    "papermill": {
     "duration": 16.056984,
     "end_time": "2023-11-28T10:10:45.856585",
     "exception": false,
     "start_time": "2023-11-28T10:10:29.799601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca13a62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:45.881264Z",
     "iopub.status.busy": "2023-11-28T10:10:45.880768Z",
     "iopub.status.idle": "2023-11-28T10:10:45.907674Z",
     "shell.execute_reply": "2023-11-28T10:10:45.906741Z"
    },
    "papermill": {
     "duration": 0.041199,
     "end_time": "2023-11-28T10:10:45.909562",
     "exception": false,
     "start_time": "2023-11-28T10:10:45.868363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/y_test.csv\n",
      "/kaggle/input/X_test.csv\n",
      "/kaggle/input/y_val.csv\n",
      "/kaggle/input/y_train.csv\n",
      "/kaggle/input/X_train.csv\n",
      "/kaggle/input/X_val.csv\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d60b3665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:45.933787Z",
     "iopub.status.busy": "2023-11-28T10:10:45.933516Z",
     "iopub.status.idle": "2023-11-28T10:10:46.004417Z",
     "shell.execute_reply": "2023-11-28T10:10:46.003645Z"
    },
    "id": "ZlwZK-zl-Lfr",
    "outputId": "97917afe-b9f8-478d-f333-69e0600c3937",
    "papermill": {
     "duration": 0.08521,
     "end_time": "2023-11-28T10:10:46.006471",
     "exception": false,
     "start_time": "2023-11-28T10:10:45.921261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    " dev = \"cuda:0\"\n",
    "else:\n",
    " dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3968f53",
   "metadata": {
    "id": "x2mdCL9NM5S1",
    "papermill": {
     "duration": 0.011104,
     "end_time": "2023-11-28T10:10:46.028892",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.017788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e010a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:46.052509Z",
     "iopub.status.busy": "2023-11-28T10:10:46.052236Z",
     "iopub.status.idle": "2023-11-28T10:10:46.062204Z",
     "shell.execute_reply": "2023-11-28T10:10:46.061362Z"
    },
    "id": "cqJSks2dp6QU",
    "papermill": {
     "duration": 0.023986,
     "end_time": "2023-11-28T10:10:46.064031",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.040045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_classification(y_test, y_pred, out_dir, labels):\n",
    "  if isinstance(y_pred, np.ndarray) == False:\n",
    "    y_pred = y_pred.toarray()\n",
    "\n",
    "  def accuracy(y_true, y_pred):\n",
    "    temp = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        numerator = sum(np.logical_and(y_true[i], y_pred[i]))\n",
    "        denominator = sum(np.logical_or(y_true[i], y_pred[i]))\n",
    "        if denominator != 0:\n",
    "          temp += numerator / denominator\n",
    "    return temp / y_true.shape[0]\n",
    "\n",
    "  out = classification_report(y_test,y_pred, output_dict=True, target_names=labels)\n",
    "  total_support = out['samples avg']['support']\n",
    "\n",
    "  mr = accuracy_score(y_test, y_pred)\n",
    "  acc = accuracy(y_test,y_pred)\n",
    "  hm = hamming_loss(y_test, y_pred)\n",
    "\n",
    "  out['Exact Match Ratio'] = {'precision': mr, 'recall': mr, 'f1-score': mr, 'support': total_support}\n",
    "  out['Hamming Loss'] = {'precision': hm, 'recall': hm, 'f1-score': hm, 'support': total_support}\n",
    "  out['Accuracy'] = {'precision': acc, 'recall': acc, 'f1-score': acc, 'support': total_support}\n",
    "  out_df = pd.DataFrame(out).transpose()\n",
    "  print(out_df)\n",
    "\n",
    "  out_df.to_csv(out_dir)\n",
    "\n",
    "  return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8ab6e5",
   "metadata": {
    "id": "FAQOzGAG1XRr",
    "papermill": {
     "duration": 0.011217,
     "end_time": "2023-11-28T10:10:46.086387",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.075170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6a332f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:46.110152Z",
     "iopub.status.busy": "2023-11-28T10:10:46.109885Z",
     "iopub.status.idle": "2023-11-28T10:10:46.128380Z",
     "shell.execute_reply": "2023-11-28T10:10:46.127654Z"
    },
    "id": "8wki3TAqGFYM",
    "papermill": {
     "duration": 0.032665,
     "end_time": "2023-11-28T10:10:46.130263",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.097598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self, num_words=None, lower=True) -> None:\n",
    "        self.word_index = {}\n",
    "        self.word_counts = {}\n",
    "        self.num_words = num_words\n",
    "        self.split = \" \"\n",
    "        self.lower = lower\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        \"\"\"\n",
    "        create vocabulary\n",
    "\n",
    "        Args:\n",
    "            text: list of strings or list of list of strings\n",
    "        \"\"\"\n",
    "        for text in texts:\n",
    "            seq = self.text_to_word_sequence(text)\n",
    "            for w in seq:\n",
    "                if w in self.word_counts:\n",
    "                    self.word_counts[w] += 1\n",
    "\n",
    "                else:\n",
    "                    self.word_counts[w] = 1\n",
    "        vocab = self.word_counts.keys()\n",
    "        self.word_index = dict(zip(vocab, list(range(1, len(vocab) + 1))))\n",
    "\n",
    "    def text_to_word_sequence(self, input_text):\n",
    "        if self.lower == True:\n",
    "            input_text = input_text.lower()\n",
    "\n",
    "        seq = input_text.split(self.split)\n",
    "        return seq\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        return list(self.texts_to_sequences_generator(texts))\n",
    "\n",
    "    def texts_to_sequences_generator(self, texts):\n",
    "        for text in texts:\n",
    "            seq = self.text_to_word_sequence(text)\n",
    "            vect = []\n",
    "            for w in seq:\n",
    "                i = self.word_index.get(w)\n",
    "                vect.append(i)\n",
    "            yield vect\n",
    "\n",
    "def pad_sequences(\n",
    "    sequences,\n",
    "    maxlen=None,\n",
    "    dtype=\"int32\",\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\",\n",
    "    value=0.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sequences: List of sequences (each sequence is a list of integers).\n",
    "        maxlen: Optional Int, maximum length of all sequences. If not provided,\n",
    "            sequences will be padded to the length of the longest individual\n",
    "            sequence.\n",
    "        dtype: (Optional, defaults to `\"int32\"`). Type of the output sequences.\n",
    "            To pad sequences with variable length strings, you can use `object`.\n",
    "        padding: String, \"pre\" or \"post\" (optional, defaults to `\"pre\"`):\n",
    "            pad either before or after each sequence.\n",
    "        truncating: String, \"pre\" or \"post\" (optional, defaults to `\"pre\"`):\n",
    "            remove values from sequences larger than\n",
    "            `maxlen`, either at the beginning or at the end of the sequences.\n",
    "        value: Float or String, padding value. (Optional, defaults to 0.)\n",
    "\n",
    "    Returns:\n",
    "        Numpy array with shape `(len(sequences), maxlen)`\n",
    "\n",
    "    Raises:\n",
    "        ValueError: In case of invalid values for `truncating` or `padding`,\n",
    "            or in case of invalid shape for a `sequences` entry.\n",
    "    \"\"\"\n",
    "\n",
    "    if not hasattr(sequences, \"__len__\"):\n",
    "        raise ValueError(\"`sequences` must be iterable.\")\n",
    "    num_samples = len(sequences)\n",
    "\n",
    "    lengths = []\n",
    "    sample_shape = ()\n",
    "    flag = True\n",
    "\n",
    "    # take the sample shape from the first non empty sequence\n",
    "    # checking for consistency in the main loop below.\n",
    "\n",
    "    for x in sequences:\n",
    "        try:\n",
    "            lengths.append(len(x))\n",
    "            if flag and len(x):\n",
    "                sample_shape = np.asarray(x).shape[1:]\n",
    "                flag = False\n",
    "        except TypeError as e:\n",
    "            raise ValueError(\n",
    "                \"`sequences` must be a list of iterables. \"\n",
    "                f\"Found non-iterable: {str(x)}\"\n",
    "            ) from e\n",
    "\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    is_dtype_str = np.issubdtype(dtype, np.str_) or np.issubdtype(\n",
    "        dtype, np.unicode_\n",
    "    )\n",
    "    if isinstance(value, str) and dtype != object and not is_dtype_str:\n",
    "        raise ValueError(\n",
    "            f\"`dtype` {dtype} is not compatible with `value`'s type: \"\n",
    "            f\"{type(value)}\\nYou should set `dtype=object` for variable length \"\n",
    "            \"strings.\"\n",
    "        )\n",
    "\n",
    "    x = np.full((num_samples, maxlen) + sample_shape, value, dtype=dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if not len(s):\n",
    "            continue  # empty list/array was found\n",
    "        if truncating == \"pre\":\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == \"post\":\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError(f'Truncating type \"{truncating}\" not understood')\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError(\n",
    "                f\"Shape of sample {trunc.shape[1:]} of sequence at \"\n",
    "                f\"position {idx} is different from expected shape \"\n",
    "                f\"{sample_shape}\"\n",
    "            )\n",
    "\n",
    "        if padding == \"post\":\n",
    "            x[idx, : len(trunc)] = trunc\n",
    "        elif padding == \"pre\":\n",
    "            x[idx, -len(trunc) :] = trunc\n",
    "        else:\n",
    "            raise ValueError(f'Padding type \"{padding}\" not understood')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe80e7",
   "metadata": {
    "id": "1q9IdP92n3xT",
    "papermill": {
     "duration": 0.011062,
     "end_time": "2023-11-28T10:10:46.152517",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.141455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62349c",
   "metadata": {
    "id": "NvxJELKhn7ny",
    "papermill": {
     "duration": 0.010937,
     "end_time": "2023-11-28T10:10:46.174533",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.163596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f357ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:46.198129Z",
     "iopub.status.busy": "2023-11-28T10:10:46.197827Z",
     "iopub.status.idle": "2023-11-28T10:10:46.203910Z",
     "shell.execute_reply": "2023-11-28T10:10:46.203200Z"
    },
    "papermill": {
     "duration": 0.019741,
     "end_time": "2023-11-28T10:10:46.205666",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.185925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Branch(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, dropout, num_outputs):\n",
    "    super(Branch, self).__init__()\n",
    "\n",
    "    self.dense1 = nn.Linear(input_size, hidden_size)\n",
    "    self.batchnorm1 = nn.BatchNorm1d(hidden_size)\n",
    "    self.dropout = nn.Dropout(p=dropout)\n",
    "    self.dense2 = nn.Linear(hidden_size, num_outputs)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # print(\"Branch Input Shape:\", x.shape)\n",
    "    out_dense1 = self.dense1(x)\n",
    "    # print(\"After Dense1 Shape:\", out_dense1.shape)\n",
    "    out_batchnorm1 = self.batchnorm1(out_dense1)\n",
    "    out_dropout = self.dropout(out_batchnorm1)\n",
    "    out_dense2 = self.dense2(out_dropout)\n",
    "\n",
    "    return out_dense2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75ede9ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:46.228965Z",
     "iopub.status.busy": "2023-11-28T10:10:46.228672Z",
     "iopub.status.idle": "2023-11-28T10:10:46.240345Z",
     "shell.execute_reply": "2023-11-28T10:10:46.239461Z"
    },
    "id": "N95V8a_125ys",
    "papermill": {
     "duration": 0.025651,
     "end_time": "2023-11-28T10:10:46.242388",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.216737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Escort(nn.Module):\n",
    "  def __init__(self, vocab_size, embedd_size, rnn_hidden_size, n_layers, num_classes, method_type, bidirectional, is_multibranches, num_auxiliary=None, auxiliary_feature_length=None):\n",
    "    super(Escort, self).__init__()\n",
    "    \n",
    "    self.word_embeddings = nn.Embedding(vocab_size, embedd_size, padding_idx=0)\n",
    "    self.bidirectional = bidirectional\n",
    "    self.is_multibranches = is_multibranches\n",
    "    if method_type=='GRU':\n",
    "        self.rnn = nn.GRU(embedd_size, rnn_hidden_size, num_layers=n_layers, batch_first=True, bidirectional=self.bidirectional)\n",
    "    else:\n",
    "        self.rnn = nn.LSTM(embedd_size, rnn_hidden_size, num_layers=n_layers, batch_first=True, bidirectional=self.bidirectional)\n",
    "    if num_auxiliary is not None and auxiliary_feature_length is not None:\n",
    "        if num_auxiliary > 2 or num_auxiliary < 0:\n",
    "            raise ValueError('num_auxiliary must be in (0,1,2)')\n",
    "        rnn_hidden_size = rnn_hidden_size + num_auxiliary*auxiliary_feature_length\n",
    "        \n",
    "    if self.is_multibranches:\n",
    "        self.branches = nn.ModuleList([Branch(rnn_hidden_size, 128, 0.2, 1) for _ in range(num_classes)])\n",
    "    else:\n",
    "        self.branch = Branch(rnn_hidden_size, 128, 0.2, num_classes)\n",
    "        \n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, sequence, tfidf_features=None,word2vec=None):\n",
    "    # print(\"Input to Escort:\", sequence.shape)\n",
    "    embeds = self.word_embeddings(sequence)\n",
    "    rnn_out, hidden = self.rnn(embeds)\n",
    "    \n",
    "    if self.bidirectional:\n",
    "        rnn_out = (rnn_out[:, :, :self.rnn_hidden_size] + rnn_out[:, :, self.rnn_hidden_size:])\n",
    "        \n",
    "    if tfidf_features is not None:\n",
    "        rnn_out = torch.cat([rnn_out, tfidf_features])\n",
    "    if word2vec is not None:\n",
    "        rnn_out = torch.cat([rnn_out, word2vec])\n",
    "    \n",
    "    if self.is_multibranches:\n",
    "        out_branch = [branch(rnn_out[:, -1, :]) for branch in self.branches]\n",
    "        out_branch = torch.cat(output_branches, dim=1)\n",
    "    else:\n",
    "        out_branch = self.branch(rnn_out[:, -1, :])\n",
    "    outputs = self.sigmoid(out_branch)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d96e4c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:46.265905Z",
     "iopub.status.busy": "2023-11-28T10:10:46.265613Z",
     "iopub.status.idle": "2023-11-28T10:10:46.274845Z",
     "shell.execute_reply": "2023-11-28T10:10:46.274148Z"
    },
    "papermill": {
     "duration": 0.023017,
     "end_time": "2023-11-28T10:10:46.276659",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.253642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OpcodeData(Dataset):\n",
    "    def __init__(self, X, y, tokenizer, tfidf, w2v_model, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.X = X.to_numpy()\n",
    "        self.targets = y\n",
    "        self.max_len = max_len\n",
    "        self.tfidf = tfidf\n",
    "        self.model = w2v_model\n",
    "        \n",
    "    def avg(self,text):\n",
    "        for x in text:\n",
    "            k = x.split()\n",
    "        word_vectors = [self.model.wv[word] for word in k]\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.X[index]\n",
    "        word2vec = self.avg(text)\n",
    "        ids = self.tokenizer.texts_to_sequences([text])[0]\n",
    "        ids = pad_sequences([ids], maxlen=self.max_len)[0]\n",
    "        tfidf_features = tfidf.transform([text]).toarray()[0]\n",
    "\n",
    "        return {\n",
    "            'index': index,\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'tfidf_features': torch.tensor(tfidf_features, dtype=torch.float),\n",
    "            'word2vec': torch.tensor(word2vec, dtype=torch.float),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "545ca9c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:46.299882Z",
     "iopub.status.busy": "2023-11-28T10:10:46.299624Z",
     "iopub.status.idle": "2023-11-28T10:10:46.305218Z",
     "shell.execute_reply": "2023-11-28T10:10:46.304465Z"
    },
    "papermill": {
     "duration": 0.019186,
     "end_time": "2023-11-28T10:10:46.307003",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.287817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_misclassified_data(labels, preds, indices):\n",
    "  misclassify_data = {}\n",
    "  for i in range(len(labels)):\n",
    "    is_append = False\n",
    "    reject_label = np.array(labels[i])\n",
    "    for j in range(len(labels[i])):\n",
    "      if labels[i, j] != preds[i, j]:\n",
    "        reject_label[j] = 2 # reject label\n",
    "        is_append = True\n",
    "\n",
    "    if is_append:\n",
    "      x_train_index = indices[i]\n",
    "      misclassify_data[x_train_index] = np.array(reject_label)\n",
    "  return misclassify_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e7f9b0",
   "metadata": {
    "id": "3BAJUkZcoAyE",
    "papermill": {
     "duration": 0.050556,
     "end_time": "2023-11-28T10:10:46.368754",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.318198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4c9ae",
   "metadata": {
    "id": "7vxHiIbwrKRS",
    "papermill": {
     "duration": 0.011039,
     "end_time": "2023-11-28T10:10:46.391048",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.380009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train and Validation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2d33114",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:46.415187Z",
     "iopub.status.busy": "2023-11-28T10:10:46.414521Z",
     "iopub.status.idle": "2023-11-28T10:10:46.429787Z",
     "shell.execute_reply": "2023-11-28T10:10:46.429075Z"
    },
    "id": "UF8lqT-M-BL6",
    "papermill": {
     "duration": 0.029511,
     "end_time": "2023-11-28T10:10:46.431730",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.402219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_steps(training_loader, model, loss_f, optimizer):\n",
    "    print('Training...')\n",
    "    training_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    train_acc = 0.\n",
    "    train_f1 = 0.\n",
    "    misclassify_train_data = {}\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(training_loader):\n",
    "        # push the batch to gpu\n",
    "        indices = batch['index'].numpy()\n",
    "        tfidf_features = batch['tfidf_features'].to(device)\n",
    "        ids = batch['ids'].to(device)\n",
    "        word2vec = batch['word2vec'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "\n",
    "        preds, max_indices = model(ids, tfidf_features=tfidf_features,word2vec=word2vec)\n",
    "\n",
    "        # calculate the loss for each branch\n",
    "        losses = [loss_f(preds[i], targets[:, i]) for i in range(targets.shape[1])]\n",
    "        average_loss = sum(losses) / targets.shape[1]\n",
    "        training_loss += average_loss.item()\n",
    "\n",
    "        label_ids = targets.to('cpu').numpy()\n",
    "        max_indices = max_indices.detach().cpu().numpy()\n",
    "        acc_score = accuracy_score(label_ids, max_indices)\n",
    "        train_acc += acc_score\n",
    "\n",
    "        misclassify_data = get_misclassified_data(label_ids, max_indices, indices)\n",
    "        misclassify_train_data.update(misclassify_data)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        average_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = training_loss / nb_tr_steps\n",
    "    epoch_acc = train_acc / nb_tr_steps\n",
    "\n",
    "    return epoch_loss, epoch_acc, misclassify_train_data\n",
    "\n",
    "\n",
    "def evaluate_steps(validating_loader, model, loss_f):\n",
    "    print(\"Evaluating...\")\n",
    "\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(validating_loader):\n",
    "        # push the batch to gpu\n",
    "        indices = batch['index'].numpy()\n",
    "        tfidf_features = batch['tfidf_features'].to(device)\n",
    "        ids = batch['ids'].to(device)\n",
    "        word2vec = batch['word2vec'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "        \n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            # model predictions\n",
    "            preds, max_indices = model(ids, attention_mask=mask, token_type_ids=token_type_ids, tfidf_features=tfidf_features,word2vec=word2vec)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            losses = [loss_f(preds[i], targets[:, i]) for i in range(targets.shape[1])]\n",
    "            average_loss = sum(losses) / targets.shape[1]\n",
    "            total_loss += average_loss.item()\n",
    "\n",
    "            max_indices = max_indices.detach().cpu().numpy()\n",
    "            total_preds += list(max_indices)\n",
    "            total_labels += targets.tolist()\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(validating_loader)\n",
    "    acc_score = accuracy_score(total_labels, total_preds)\n",
    "\n",
    "    return avg_loss, acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d2d721",
   "metadata": {
    "id": "sZ9uzmMGsOhR",
    "papermill": {
     "duration": 0.011075,
     "end_time": "2023-11-28T10:10:46.453924",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.442849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51e714ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:46.477308Z",
     "iopub.status.busy": "2023-11-28T10:10:46.477069Z",
     "iopub.status.idle": "2023-11-28T10:10:46.485325Z",
     "shell.execute_reply": "2023-11-28T10:10:46.484470Z"
    },
    "id": "rQ82Aqtbpifd",
    "papermill": {
     "duration": 0.022169,
     "end_time": "2023-11-28T10:10:46.487255",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.465086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epochs, model, optimizer, criterion, dataloader, save_model_dir):\n",
    "  data_train_loader, data_val_loader = dataloader\n",
    "  # set initial loss to infinite\n",
    "  best_valid_loss = float('inf')\n",
    "  train_losses = []\n",
    "  valid_losses = []\n",
    "  train_accuracies = []\n",
    "  valid_accuracies = []\n",
    "  misclassify_train_data = {}\n",
    "  total_time = 0.0\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    print('Epoch {}/{} '.format(epoch + 1, epochs))\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc, misclassify_train_steps_data = train_steps(data_train_loader, model, criterion, optimizer)\n",
    "    valid_loss, valid_acc = evaluate_steps(data_val_loader, model, criterion)\n",
    "\n",
    "    # save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_model_dir)\n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    valid_accuracies.append(valid_acc)\n",
    "    misclassify_train_data.update(misclassify_train_steps_data)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    total_time += elapsed_time\n",
    "\n",
    "    print('\\t loss={:.4f} \\t accuracy={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(train_loss, train_acc, valid_loss, valid_acc, elapsed_time))\n",
    "  print(f'Total time: {total_time}')\n",
    "  return train_accuracies, valid_accuracies, train_losses, valid_losses, misclassify_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ff1d218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:46.510718Z",
     "iopub.status.busy": "2023-11-28T10:10:46.510459Z",
     "iopub.status.idle": "2023-11-28T10:10:46.516119Z",
     "shell.execute_reply": "2023-11-28T10:10:46.515299Z"
    },
    "id": "yNXt80cVsWgx",
    "papermill": {
     "duration": 0.019514,
     "end_time": "2023-11-28T10:10:46.518013",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.498499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_graph(epochs, train, valid, tittle):\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    plt.title(tittle)\n",
    "    plt.plot(list(np.arange(epochs) + 1) , train, label='train')\n",
    "    plt.plot(list(np.arange(epochs) + 1), valid, label='validation')\n",
    "    plt.xlabel('num_epochs', fontsize=12)\n",
    "    plt.ylabel('loss', fontsize=12)\n",
    "    plt.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368bfa1a",
   "metadata": {
    "id": "VXnRPRFDwxle",
    "papermill": {
     "duration": 0.010999,
     "end_time": "2023-11-28T10:10:46.540330",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.529331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dbd791c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:46.564006Z",
     "iopub.status.busy": "2023-11-28T10:10:46.563364Z",
     "iopub.status.idle": "2023-11-28T10:10:46.570470Z",
     "shell.execute_reply": "2023-11-28T10:10:46.569640Z"
    },
    "id": "soXxXY8yw3Er",
    "papermill": {
     "duration": 0.020704,
     "end_time": "2023-11-28T10:10:46.572206",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.551502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(testing_loader, model):\n",
    "    print(\"\\nPredicting...\")\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(testing_loader):\n",
    "        # push the batch to gpu\n",
    "        indices = batch['index'].numpy()\n",
    "        tfidf_features = batch['tfidf_features'].to(device)\n",
    "        ids = batch['ids'].to(device)\n",
    "        word2vec = batch['word2vec'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            # model predictions\n",
    "            preds, max_indices = model(ids, attention_mask=mask, token_type_ids=token_type_ids, tfidf_features=tfidf_features,word2vec=word2vec)\n",
    "\n",
    "            max_indices = max_indices.detach().cpu().numpy()\n",
    "            total_preds += list(max_indices)\n",
    "            total_labels += targets.tolist()\n",
    "\n",
    "    return total_labels, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341df31",
   "metadata": {
    "id": "9H2Jpz4Qx0MC",
    "papermill": {
     "duration": 0.010821,
     "end_time": "2023-11-28T10:10:46.594214",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.583393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "109323e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:46.617560Z",
     "iopub.status.busy": "2023-11-28T10:10:46.617256Z",
     "iopub.status.idle": "2023-11-28T10:10:46.623405Z",
     "shell.execute_reply": "2023-11-28T10:10:46.622568Z"
    },
    "papermill": {
     "duration": 0.020012,
     "end_time": "2023-11-28T10:10:46.625346",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.605334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder='/kaggle/input/'\n",
    "out_folder ='/kaggle/working/'\n",
    "# Define constant\n",
    "input_size = 4100\n",
    "epochs = 1\n",
    "SIZE_OF_VOCAB = 512\n",
    "EMBEDDED_SIZE = 5\n",
    "GRU_HIDDEN_SIZE = 256\n",
    "NUM_OUTPUT_NODES = 4\n",
    "NUM_LAYERS = 1\n",
    "DROPOUT = 0.2\n",
    "RNN_TYPE = 'GRU'\n",
    "BIDIRECTIONAL = True\n",
    "USE_MULTIBRANCHES = True\n",
    "LEARNING_RATE=1e-3\n",
    "labels = ['Timestamp dependence', 'Outdated Solidity version', 'Frozen Ether', 'Delegatecall Injection']\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "save_model_dir = out_folder + 'escort-tfidf-w2v.pt'\n",
    "report_dir = out_folder + 'escort-tfidf-w2v.csv'\n",
    "tokenizer_dir = out_folder + 'tokenizer.pickle'\n",
    "w2v_dir = out_folder + 'fasttext_w2v.pickle'\n",
    "tfidf_dir = out_folder + 'tfidf.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3adf710a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:10:46.648891Z",
     "iopub.status.busy": "2023-11-28T10:10:46.648611Z",
     "iopub.status.idle": "2023-11-28T10:12:35.608554Z",
     "shell.execute_reply": "2023-11-28T10:12:35.607675Z"
    },
    "id": "CdrqOWprL6G1",
    "papermill": {
     "duration": 108.974468,
     "end_time": "2023-11-28T10:12:35.611029",
     "exception": false,
     "start_time": "2023-11-28T10:10:46.636561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# data_folder = os.getcwd()+'/Wisdomnet/Untitled Folder/'\n",
    "# out_folder = os.getcwd()+'/trained/'\n",
    "# Read data\n",
    "X_train = pd.read_csv(data_folder+'X_train.csv')\n",
    "X_test = pd.read_csv(data_folder+'X_test.csv')\n",
    "X_val = pd.read_csv(data_folder+'X_val.csv')\n",
    "\n",
    "y_train = pd.read_csv(data_folder+'y_train.csv').to_numpy()\n",
    "y_test = pd.read_csv(data_folder+'y_test.csv').to_numpy()\n",
    "y_val = pd.read_csv(data_folder+'y_val.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6046329b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:12:35.635427Z",
     "iopub.status.busy": "2023-11-28T10:12:35.635125Z",
     "iopub.status.idle": "2023-11-28T10:19:27.021604Z",
     "shell.execute_reply": "2023-11-28T10:19:27.020538Z"
    },
    "papermill": {
     "duration": 411.401279,
     "end_time": "2023-11-28T10:19:27.024180",
     "exception": false,
     "start_time": "2023-11-28T10:12:35.622901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts=np.copy(X_train['BYTECODE'].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d53d05ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:19:27.049591Z",
     "iopub.status.busy": "2023-11-28T10:19:27.049264Z",
     "iopub.status.idle": "2023-11-28T10:34:59.018232Z",
     "shell.execute_reply": "2023-11-28T10:34:59.017392Z"
    },
    "papermill": {
     "duration": 931.984426,
     "end_time": "2023-11-28T10:34:59.020604",
     "exception": false,
     "start_time": "2023-11-28T10:19:27.036178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=256)\n",
    "tfidf_features = tfidf.fit_transform(np.copy(X_train['BYTECODE'].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ade2976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:34:59.045258Z",
     "iopub.status.busy": "2023-11-28T10:34:59.044967Z",
     "iopub.status.idle": "2023-11-28T10:47:15.984208Z",
     "shell.execute_reply": "2023-11-28T10:47:15.983169Z"
    },
    "papermill": {
     "duration": 736.954214,
     "end_time": "2023-11-28T10:47:15.986663",
     "exception": false,
     "start_time": "2023-11-28T10:34:59.032449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "splits = []\n",
    "for sentence in X_train['BYTECODE'].tolist():\n",
    "    for x in sentence:\n",
    "        l = x.split(' ')\n",
    "    splits.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2413ec76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:47:16.010906Z",
     "iopub.status.busy": "2023-11-28T10:47:16.010578Z",
     "iopub.status.idle": "2023-11-28T10:47:20.892688Z",
     "shell.execute_reply": "2023-11-28T10:47:20.891902Z"
    },
    "papermill": {
     "duration": 4.896551,
     "end_time": "2023-11-28T10:47:20.894963",
     "exception": false,
     "start_time": "2023-11-28T10:47:15.998412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "word2vec = FastText(splits, min_count=1, window=7,vector_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ba8e7ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:47:20.919059Z",
     "iopub.status.busy": "2023-11-28T10:47:20.918762Z",
     "iopub.status.idle": "2023-11-28T10:47:20.924551Z",
     "shell.execute_reply": "2023-11-28T10:47:20.923761Z"
    },
    "papermill": {
     "duration": 0.019646,
     "end_time": "2023-11-28T10:47:20.926309",
     "exception": false,
     "start_time": "2023-11-28T10:47:20.906663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model, save_model_dir):\n",
    "    try:\n",
    "        with open(save_model_dir, 'wb') as file:\n",
    "            pickle.dump(model, file)\n",
    "        print(f'save successfully model with {save_model_dir}')\n",
    "\n",
    "    except:\n",
    "        print(f'can\\'t save model with {save_model_dir}')\n",
    "\n",
    "def load_model(save_model_dir):\n",
    "    with open(save_model_dir, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b642a4b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:47:20.949889Z",
     "iopub.status.busy": "2023-11-28T10:47:20.949592Z",
     "iopub.status.idle": "2023-11-28T10:47:20.953120Z",
     "shell.execute_reply": "2023-11-28T10:47:20.952323Z"
    },
    "papermill": {
     "duration": 0.017244,
     "end_time": "2023-11-28T10:47:20.954882",
     "exception": false,
     "start_time": "2023-11-28T10:47:20.937638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save_model(tokenizer, tokenizer_dir)\n",
    "# save_model(tfidf, tfidf_dir)\n",
    "# save_model(word2vec, w2v_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b7b95a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:47:20.978178Z",
     "iopub.status.busy": "2023-11-28T10:47:20.977935Z",
     "iopub.status.idle": "2023-11-28T10:47:20.981498Z",
     "shell.execute_reply": "2023-11-28T10:47:20.980751Z"
    },
    "papermill": {
     "duration": 0.017317,
     "end_time": "2023-11-28T10:47:20.983362",
     "exception": false,
     "start_time": "2023-11-28T10:47:20.966045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# word2vec = FastText(vector_size=256, window=7, min_count=1, sentences=splits, epochs=10, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e99c3aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:47:21.007198Z",
     "iopub.status.busy": "2023-11-28T10:47:21.006942Z",
     "iopub.status.idle": "2023-11-28T10:47:21.012144Z",
     "shell.execute_reply": "2023-11-28T10:47:21.011315Z"
    },
    "papermill": {
     "duration": 0.019513,
     "end_time": "2023-11-28T10:47:21.014010",
     "exception": false,
     "start_time": "2023-11-28T10:47:20.994497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = OpcodeData(X=X_train, y=y_train, tokenizer=tokenizer, tfidf=tfidf, w2v_model=word2vec, max_len=input_size)\n",
    "test_dataset = OpcodeData(X=X_test, y=y_test, tokenizer=tokenizer, tfidf=tfidf, w2v_model=word2vec, max_len=input_size)\n",
    "val_dataset = OpcodeData(X=X_val, y=y_val, tokenizer=tokenizer, tfidf=tfidf, w2v_model=word2vec, max_len=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3a72feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:47:21.037488Z",
     "iopub.status.busy": "2023-11-28T10:47:21.037233Z",
     "iopub.status.idle": "2023-11-28T10:47:21.041716Z",
     "shell.execute_reply": "2023-11-28T10:47:21.041012Z"
    },
    "papermill": {
     "duration": 0.018197,
     "end_time": "2023-11-28T10:47:21.043582",
     "exception": false,
     "start_time": "2023-11-28T10:47:21.025385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create generator for Dataset with BATCH_SIZE\n",
    "training_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE)\n",
    "validating_loader = DataLoader(val_dataset, batch_size=VALID_BATCH_SIZE)\n",
    "testing_loader = DataLoader(test_dataset, batch_size=VALID_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba1964f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:47:21.066977Z",
     "iopub.status.busy": "2023-11-28T10:47:21.066685Z",
     "iopub.status.idle": "2023-11-28T10:47:21.070337Z",
     "shell.execute_reply": "2023-11-28T10:47:21.069594Z"
    },
    "papermill": {
     "duration": 0.01724,
     "end_time": "2023-11-28T10:47:21.072201",
     "exception": false,
     "start_time": "2023-11-28T10:47:21.054961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = next(iter(validating_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "193f093b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:47:21.095866Z",
     "iopub.status.busy": "2023-11-28T10:47:21.095591Z",
     "iopub.status.idle": "2023-11-28T10:47:26.123236Z",
     "shell.execute_reply": "2023-11-28T10:47:26.122120Z"
    },
    "id": "vTM0v9sK3nCZ",
    "papermill": {
     "duration": 5.042022,
     "end_time": "2023-11-28T10:47:26.125412",
     "exception": false,
     "start_time": "2023-11-28T10:47:21.083390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escort(\n",
      "  (word_embeddings): Embedding(512, 5, padding_idx=0)\n",
      "  (rnn): GRU(5, 256, batch_first=True, bidirectional=True)\n",
      "  (branches): ModuleList(\n",
      "    (0-3): 4 x Branch(\n",
      "      (dense1): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (batchnorm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (dense2): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = Escort(SIZE_OF_VOCAB, EMBEDDED_SIZE, GRU_HIDDEN_SIZE, NUM_LAYERS, NUM_OUTPUT_NODES, RNN_TYPE, BIDIRECTIONAL, USE_MULTIBRANCHES)\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3b51fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:47:26.150461Z",
     "iopub.status.busy": "2023-11-28T10:47:26.149727Z",
     "iopub.status.idle": "2023-11-28T10:47:26.447018Z",
     "shell.execute_reply": "2023-11-28T10:47:26.445813Z"
    },
    "id": "HE-t7X_TMf6m",
    "papermill": {
     "duration": 0.311512,
     "end_time": "2023-11-28T10:47:26.448679",
     "exception": true,
     "start_time": "2023-11-28T10:47:26.137167",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() missing 1 required positional argument: 'save_model_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_accuracies, valid_accuracies, train_losses, valid_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: train() missing 1 required positional argument: 'save_model_dir'"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train_accuracies, valid_accuracies, train_losses, valid_losses = train(epochs, model, optimizer, criterion, save_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f61707d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-28T03:39:15.904372Z",
     "iopub.status.idle": "2023-11-28T03:39:15.904709Z",
     "shell.execute_reply": "2023-11-28T03:39:15.904557Z",
     "shell.execute_reply.started": "2023-11-28T03:39:15.904540Z"
    },
    "id": "n0ftnFQa3k34",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot graph\n",
    "plot_graph(epochs, train_losses, valid_losses, \"Train/Validation Loss\")\n",
    "plot_graph(epochs, train_accuracies, valid_accuracies, \"Train/Validation Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1cd1a4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-28T03:39:15.906190Z",
     "iopub.status.idle": "2023-11-28T03:39:15.906542Z",
     "shell.execute_reply": "2023-11-28T03:39:15.906392Z",
     "shell.execute_reply.started": "2023-11-28T03:39:15.906375Z"
    },
    "id": "pELUFirP3Kcx",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test model\n",
    "total_preds, total_labels, execution_time = predict(data_test_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442dfdeb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-28T03:39:15.908755Z",
     "iopub.status.idle": "2023-11-28T03:39:15.909200Z",
     "shell.execute_reply": "2023-11-28T03:39:15.908991Z",
     "shell.execute_reply.started": "2023-11-28T03:39:15.908970Z"
    },
    "id": "SkKf6FVD5NVW",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8f126",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-28T03:39:15.910688Z",
     "iopub.status.idle": "2023-11-28T03:39:15.911117Z",
     "shell.execute_reply": "2023-11-28T03:39:15.910914Z",
     "shell.execute_reply.started": "2023-11-28T03:39:15.910893Z"
    },
    "id": "KoxRi-3x4JGY",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_classification(y_pred=np.array(total_preds), y_test=np.array(total_labels), labels=labels, out_dir=report_dir)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3740786,
     "sourceId": 6476634,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2222.276975,
   "end_time": "2023-11-28T10:47:28.776953",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-28T10:10:26.499978",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
